{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "satisfied-macintosh",
   "metadata": {},
   "source": [
    "# Prepare problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-legislation",
   "metadata": {},
   "source": [
    "***Load libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-determination",
   "metadata": {},
   "source": [
    "***Load the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('churn.all2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-violence",
   "metadata": {},
   "source": [
    "# Data exploration & cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-journalism",
   "metadata": {},
   "source": [
    "Let us first see the column names and the number of unique values in each column. These will give us some idea about the level of measurement we have in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    print('{} : {}'.format(col, len(pd.unique(df[col]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-crime",
   "metadata": {},
   "source": [
    "It seems like ***area_code***, ***intl_plan***, ***voice_mail_plan***, and ***churned*** are categorical variables. The other variables seem to be metric (or continous). The ***state*** and ***phone_number*** variables is probably also categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-shakespeare",
   "metadata": {},
   "source": [
    "The ***state*** variable is categorical. The dataset is not a very large one. This variable probably will not help us predict anything. There are 51 unique values in this vairable, and we have 5000 cases. So, I will drop this variable.\n",
    "\n",
    "Note: The common term used for variables are ***features***, but I will keep using ***variables***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.phone_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-cooper",
   "metadata": {},
   "source": [
    "Just like the ***state*** variable, the ***phone_number*** variable is also categorical and it will not help us predict anything. Therefore, I will drop that variable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.area_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-browser",
   "metadata": {},
   "source": [
    "Similarly, the ***area_code*** is also a categorical variable. There are only three unique values in this variable. It can help us predict the outcome. For that, I need to use OneHotEncoder. But, I do not think it is worth the effort. (Note: I am being lazy here) I will drop this variable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['state','area_code','phone_number'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-rover",
   "metadata": {},
   "source": [
    "Let us see how our data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print('{}\\n{}\\n'.format(col, np.array(df[col])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-threshold",
   "metadata": {},
   "source": [
    "It looks like we have four string variables (i.e., ***intl_plan***, ***voice_mail_plan***, ***total_eve_charge***, and ***churned***). We will need to convert these variables in to numbers. Let us do it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intl_plan\n",
    "intl_plan = np.zeros(df.shape[0])\n",
    "intl_plan[df.intl_plan == ' yes'] = 1\n",
    "df.intl_plan = intl_plan\n",
    "\n",
    "# voice_mail_plan\n",
    "voice_mail_plan = np.zeros(df.shape[0])\n",
    "voice_mail_plan[df.voice_mail_plan == ' yes'] = 1\n",
    "df.voice_mail_plan = voice_mail_plan\n",
    "\n",
    "# total_eve_charge\n",
    "df.total_eve_charge = pd.to_numeric(df.total_eve_charge, errors = 'coerce')\n",
    "\n",
    "# churned\n",
    "churned = np.zeros(df.shape[0])\n",
    "churned[df.churned == ' True.'] = 1\n",
    "df.churned = churned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-lodging",
   "metadata": {},
   "source": [
    "Now, let us see if we have any NaN values in any of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-residence",
   "metadata": {},
   "source": [
    "It seems like we have a missing values in ***total_eve_charge*** and ***total_intl_charge*** variables. We can replace the missing values with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_eve_charge.fillna(value = df.total_eve_charge.mean(), inplace = True)\n",
    "df.total_intl_charge.fillna(value = df.total_intl_charge.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-strap",
   "metadata": {},
   "source": [
    "# Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-saskatchewan",
   "metadata": {},
   "source": [
    "Now let us see the correlations between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-ebony",
   "metadata": {},
   "source": [
    "The following four variables are highly correlated with other four variables in the dataset:\n",
    "\n",
    "1. total_day_charge\n",
    "2. total_eve_charge\n",
    "3. total_night_charge\n",
    "4. total_intl_charge\n",
    "\n",
    "We do not need these variables. Therefore, I will drop them.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['total_day_charge','total_eve_charge','total_night_charge','total_intl_charge'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-austria",
   "metadata": {},
   "source": [
    "We are left with the following columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-affair",
   "metadata": {},
   "source": [
    "The distribution of the **number_vmail_messages** variable was not normal or symetric. Most of the clients had zero values for this variable and some of them had non-zero values. Therefore, I converted this variable to a dummy vairable. See the distribution below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.number_vmail_messages.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.number_vmail_messages > 0, 'number_vmail_messages'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-paint",
   "metadata": {},
   "source": [
    "Now let us see how the continuous variables are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.account_length.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_day_minutes.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_day_calls.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_eve_minutes.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_eve_calls.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_night_minutes.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_night_calls.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_intl_minutes.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_intl_calls.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.number_customer_service_calls.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-kitty",
   "metadata": {},
   "source": [
    "All the continuous variables have symetric distributions, except the last two (i.e., ***total_intl_calls*** and ***number_customer_service_calls***). It seems like I do not need to transform any of the continuous variables except standardizing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-hepatitis",
   "metadata": {},
   "source": [
    "Let us see the frequency distributions of the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-briefing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in ['voice_mail_plan', 'number_vmail_messages', 'churned']:\n",
    "    print('column name: {}\\n{}\\n'.format(col, df[col].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-commerce",
   "metadata": {},
   "source": [
    "All looks good. But, the dataset is unbalanced. There are 707 positive cases and 4293 negative cases. If I train the dataset as is, it will be trained based on negative values. In that case, I will probably have high accuracy, but I may have lower recall or precision. Therefore, I will train the dataset in two different ways. First, I will use the entire dataset and see what I get. Then, I will oversample the positive cases and train the data again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-negotiation",
   "metadata": {},
   "source": [
    "# Run three algorithms using unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input and output matrices, split them into train and test\n",
    "df_ = df.values\n",
    "X = np.array(df_[:,:-1])\n",
    "y = np.array(df_[:,-1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input variables using the standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-president",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic regression model using the train set\n",
    "logreg = LogisticRegression(solver = 'lbfgs')\n",
    "logreg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the score (accuracy)\n",
    "logreg.score(X_test_scaled, y_test.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(LogisticRegression(), X_train_scaled, y_train, cv = 10)\n",
    "np.mean(cvs), np.std(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-article",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a confusion matrix and see precision and recall\n",
    "cm = confusion_matrix(y_test, logreg.predict(X_test_scaled))\n",
    "print('recall: {}'.format(cm[1,1] / sum(cm[1])))\n",
    "print('precision: {}'.format(cm[1,1] / (cm[0,1] + cm[1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-blackberry",
   "metadata": {},
   "source": [
    "In the first run (see above), although accuracy is high, recall and precision are very low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-tumor",
   "metadata": {},
   "source": [
    "**Voting Classifier:** ***Logistic regression + decision tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an ensemble model and see if anything changes\n",
    "# Create the model and fit\n",
    "voting = VotingClassifier([('logreg', LogisticRegression(C=100, solver='lbfgs')),\n",
    "                          ('tree', DecisionTreeClassifier(max_depth=3))], voting = 'soft', flatten_transform=False)\n",
    "voting.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-nowhere",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See the score (accuracy)\n",
    "voting.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(\n",
    "    VotingClassifier([('logreg', LogisticRegression(C=100, solver='lbfgs')),\n",
    "                      ('tree', DecisionTreeClassifier(max_depth=3))], voting = 'soft', flatten_transform=False),\n",
    "                    X_train_scaled, y_train, cv = 10)\n",
    "np.mean(cvs), np.std(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix and see precision and recall\n",
    "cm = confusion_matrix(y_test, voting.predict(X_test_scaled))\n",
    "print('recall: {}'.format(cm[1,1] / sum(cm[1])))\n",
    "print('precision: {}'.format(cm[1,1] / (cm[0,1] + cm[1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-clone",
   "metadata": {},
   "source": [
    "Again, in this second case (see above), the accuracy is high. Precision is also better. But recall is still too low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-theory",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us try another ensemble model, random forest.\n",
    "rf = RandomForestClassifier(n_estimators = 10, warm_start=True)\n",
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(RandomForestClassifier(), X_train_scaled, y_train, cv = 10)\n",
    "np.mean(cvs), np.std(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix and see precision and recall\n",
    "cm = confusion_matrix(y_test, rf.predict(X_test_scaled))\n",
    "print('recall: {}'.format(cm[1,1] / sum(cm[1])))\n",
    "print('precision: {}'.format(cm[1,1] / (cm[0,1] + cm[1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-fiction",
   "metadata": {},
   "source": [
    "This is much better. Both recall and precision are high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-thompson",
   "metadata": {},
   "source": [
    "# Run three algorithms using balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-motivation",
   "metadata": {},
   "source": [
    "Now, I will make a balanced dataset and train that dataset. \n",
    "\n",
    "The next cell creates the balanced dataset. Here is how I do that. First, I select all positive cases. Then, I select a sample from the negative cases, and this sample's size is the same as the number of positive cases in the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.loc[df.churned == 0]\n",
    "dft = df.loc[df.churned == 1]\n",
    "df_ = pd.concat([dft, dff.sample(dft.shape[0])])\n",
    "df_ = df_.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-selling",
   "metadata": {},
   "source": [
    "From now on, I repeat the same exact steps that I followed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_[:,:-1])\n",
    "y = np.array(df_[:,-1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-gazette",
   "metadata": {},
   "source": [
    "**Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = 'lbfgs')\n",
    "logreg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_test_scaled, y_test.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(LogisticRegression(), X_train_scaled, y_train, cv = 10)\n",
    "np.mean(cvs), np.std(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, logreg.predict(X_test_scaled))\n",
    "print('recall: {}'.format(cm[1,1] / sum(cm[1])))\n",
    "print('precision: {}'.format(cm[1,1] / (cm[0,1] + cm[1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-accordance",
   "metadata": {},
   "source": [
    "Both recall and precision are good. Can be better maybe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-complex",
   "metadata": {},
   "source": [
    "**Voting classifier:** ***Logistic regression + decision tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier([('logreg', LogisticRegression(C=100, solver='lbfgs')),\n",
    "                          ('tree', DecisionTreeClassifier(max_depth=3))], voting = 'soft', flatten_transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(\n",
    "    VotingClassifier([('logreg', LogisticRegression(C=100, solver='lbfgs')),\n",
    "                      ('tree', DecisionTreeClassifier(max_depth=3))], voting = 'soft', flatten_transform=False),\n",
    "                    X_train_scaled, y_train, cv = 10)\n",
    "np.mean(cvs), np.std(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, voting.predict(X_test_scaled))\n",
    "print('recall: {}'.format(cm[1,1] / sum(cm[1])))\n",
    "print('precision: {}'.format(cm[1,1] / (cm[0,1] + cm[1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-center",
   "metadata": {},
   "source": [
    "They are better now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-movement",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 10, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(RandomForestClassifier(), X_train_scaled, y_train, cv = 10)\n",
    "np.mean(cvs), np.std(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, rf.predict(X_test_scaled))\n",
    "print('recall: {}'.format(cm[1,1] / sum(cm[1])))\n",
    "print('precision: {}'.format(cm[1,1] / (cm[0,1] + cm[1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-breakfast",
   "metadata": {},
   "source": [
    "They are both good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-afternoon",
   "metadata": {},
   "source": [
    "Among all the models that I tried above, random forest is the best model. Voting classifier is also as good as random forest. I could do some paramater tuning to improve the models. I will try that on random forest, because it is easier to do. I could adjust the debth of the trees, number of trees, and maybe the minimum size of leaves. I will try only one of these options; I will search for the optimum number of trees. For it takes a lot of time to run grid search and random forests, I will limit the number of trees between 5 and 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = {'n_estimators': np.arange(5, 50, 5)}\n",
    "\n",
    "grid = GridSearchCV(rf, param_grid = param, cv = 10)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_.get('n_estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-christmas",
   "metadata": {},
   "source": [
    "Now let us create a random forest using the optimum number of trees, and then see the precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = grid.best_params_.get('n_estimators'), warm_start=True)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, rf.predict(X_test_scaled))\n",
    "print('recall: {}'.format(cm[1,1] / sum(cm[1])))\n",
    "print('precision: {}'.format(cm[1,1] / (cm[0,1] + cm[1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-english",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
